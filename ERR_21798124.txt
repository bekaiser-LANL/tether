/var/spool/slurmd/job21798124/slurm_script: line 19: /lustre/scratch5/dmperez/llms/conda_envs/llm/etc/profile.d/conda.sh: No such file or directory

CondaError: Run 'conda init' before 'conda activate'

None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
Traceback (most recent call last):
  File "/users/dmperez/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1817, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/usr/projects/hpcsoft/common/x86_64/anaconda/2021.11-python-3.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/users/dmperez/.local/lib/python3.9/site-packages/transformers/models/auto/processing_auto.py", line 29, in <module>
    from ...processing_utils import ProcessorMixin
  File "/users/dmperez/.local/lib/python3.9/site-packages/transformers/processing_utils.py", line 77, in <module>
    Unpack = typing_extensions.Unpack
AttributeError: module 'typing_extensions' has no attribute 'Unpack'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/lustre/scratch5/.mdt1/dmperez/tether/generate.py", line 3, in <module>
    from source.generator import generate_benchmarks
  File "/lustre/scratch5/.mdt1/dmperez/tether/source/__init__.py", line 5, in <module>
    from . import proctor
  File "/lustre/scratch5/.mdt1/dmperez/tether/source/proctor.py", line 11, in <module>
    from transformers import AutoTokenizer, AutoModelForCausalLM, AutoProcessor, MllamaForConditionalGeneration
  File "<frozen importlib._bootstrap>", line 1055, in _handle_fromlist
  File "/users/dmperez/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1806, in __getattr__
    value = getattr(module, name)
  File "/users/dmperez/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1805, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/users/dmperez/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1819, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.auto.processing_auto because of the following error (look up to see its traceback):
module 'typing_extensions' has no attribute 'Unpack'
